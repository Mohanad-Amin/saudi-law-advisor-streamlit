import streamlit as st
import os
from dotenv import load_dotenv

# Make sure you have an __init__.py file in the 'core' directory
from core.law_retriever import LawRetriever

# --- Page Configuration ---
st.set_page_config(
    page_title="Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ",
    page_icon="âš–ï¸",
    layout="centered"
)

# --- Environment Variables & Secrets ---
load_dotenv()
# For local development, create a .env file with your OPENAI_API_KEY
# For Streamlit Cloud, set the secret in the app settings
openai_api_key = os.getenv("OPENAI_API_KEY") or st.secrets.get("OPENAI_API_KEY")
if not openai_api_key:
    st.error("Ù…ÙØªØ§Ø­ OpenAI API ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¶Ø§ÙØªÙ‡ Ù„Ù…Ù„Ù .env Ø£Ùˆ ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø³Ø­Ø§Ø¨ÙŠØ©.")
    st.stop()

# --- Load Retriever (Cached for Performance) ---
@st.cache_resource
def load_retriever_system():
    """Loads the LawRetriever instance using Streamlit's caching."""
    print("Initializing LawRetriever for the first time...")
    try:
        # We will use your fine-tuned model for consistency and to showcase your skills
        retriever_instance = LawRetriever(
            model_name="TheMohanad1/Fine-Tuned-E5",
            openai_api_key=openai_api_key
        )
        print("LawRetriever loaded successfully.")
        return retriever_instance
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙØ§Ø¯Ø­ Ø£Ø«Ù†Ø§Ø¡ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…: {e}")
        st.stop()

retriever = load_retriever_system()

# --- Chat Interface ---
st.title("âš–ï¸ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ø§Ù„Ø°ÙƒÙŠ")
st.caption("Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ù„ÙÙ‡Ù… Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©")

# Initialize chat history in session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Display previous chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Handle user input
if prompt := st.chat_input("Ø§Ø³Ø£Ù„ Ø¹Ù† Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ù…Ù„, Ø§Ù„Ø´Ø±ÙƒØ§Øª, ..."):
    # Add user message to history and display it
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate and display assistant's response
    with st.chat_message("assistant"):
        with st.spinner("...Ø£Ø¨Ø­Ø« ÙÙŠ Ù†ØµÙˆØµ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"):
            
            # The retriever will access the full history from session_state
            result = retriever.search_and_answer(
                query=prompt,
                chat_history=st.session_state.messages
            )
            
            response_text = result.get("answer", "Ø¹ÙÙˆØ§Ù‹ØŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø¥ÙŠØ¬Ø§Ø¯ Ø¥Ø¬Ø§Ø¨Ø©.")
            sources = result.get("sources", [])

            st.markdown(response_text)
            
            # Display sources in an expander
            if sources:
                with st.expander("ğŸ“š Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©"):
                    for i, source in enumerate(sources):
                        # The source content is now nested in 'law_text'
                        st.write(f"**Ø§Ù„Ù…ØµØ¯Ø± Ø±Ù‚Ù… [{i+1}]** (Ø§Ù„Ù…Ø§Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ø±Ù‚Ù…: {source.get('source_index', 'N/A')})")
                        st.info(source.get('law_text', 'Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ Ù„Ù„Ù…ØµØ¯Ø±.'))
                        st.markdown("---")

    # Add assistant response to chat history, including the sources for future re-ranking
    st.session_state.messages.append({
        "role": "assistant",
        "content": response_text,
        "sources": sources # Store sources in session state
    })

